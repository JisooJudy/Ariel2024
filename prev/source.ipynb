{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random \n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import ScalarFormatter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.losses import MeanAbsoluteError\n",
    "\n",
    "from keras.layers import Input, Conv1D, MaxPooling1D, Flatten, Dense, Dropout, BatchNormalization, Concatenate,AveragePooling1D\n",
    "from keras.models import Model, load_model\n",
    "\n",
    "from keras.optimizers import Adam, RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed=42):    \n",
    "    '''랜덤시드 고정. Hyperparm tuning 제외 모든 학습환경에서 \n",
    "    같은 성능이 나오게 합니다.'''\n",
    "    tf.random.set_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Tensorflow GPU availability: \", tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = './data/'\n",
    "train_np = np.load(DATA_PATH+ 'data_train.npy', mmap_mode='r')\n",
    "train_fgs_np = np.load(DATA_PATH + 'data_train_FGS.npy', mmap_mode='r')\n",
    "\n",
    "print(f'Train data shape: {train_np}')\n",
    "print(f'Train FGS data shape: {train_fgs_np.shape}')\n",
    "\n",
    "train_sample = []\n",
    "train_fgs_sample = []\n",
    "for i in tqdm(range(len(train_np)), desc='loading train data'):\n",
    "    train_sample.append(train_np[i])\n",
    "    \n",
    "for i in tqdm(range(len(train_fgs_np)), desc='loading train FGS data'):\n",
    "    train_fgs_sample.append(train_fgs_np[i])\n",
    "    \n",
    "train = np.array(train_sample)\n",
    "train_fgs = np.array(train_fgs_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''실험 기본 셋업'''\n",
    "''' 기본 Approach - 1D CNN으로 mean 값 뽑아낸 후 2D CNN으로 구체적인 내용 뽑기'''\n",
    "TUNING_MODE = 'OFF' # ON/OFF\n",
    "\n",
    "METRIC1 = 'MeanAbsoluteError'\n",
    "METRIC2 = 'MeanAbsoluteError'\n",
    "\n",
    "OPTIMIZER = 'adam' # adam, rmsprop\n",
    "LR = 0.001   #adam과 rmsprop의 defaut값\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 15\n",
    "\n",
    "#-------아직 구현 안 된 부분-------\n",
    "\n",
    "DECAY_RATE=0.2\n",
    "DECAY_STEP=200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train_np\n",
    "train_fgs = train_fgs_np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 차후 learning rate decay 하는 scheduler도 train함수에 도입할 것. 현재는 없음.\n",
    "def scheduler(epoch, lr, decay_rate, decay_step):\n",
    "    if epoch%decay_step == 0 and epoch:\n",
    "        return lr * decay_rate\n",
    "    return lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_1d_cnn(trial=None):\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(Conv1D(32, 3, activation='relu'))\n",
    "    model.add(MaxPooling1D(pool_size=(2,2), padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv1D(64, 3, activation='relu'))\n",
    "    model.add(MaxPooling1D(pool_size=(2,2), padding='same'))\n",
    "    model.add(Conv1D(128, 3, activation='relu'))\n",
    "    model.add(MaxPooling1D(pool_size=(2,2), padding='same'))\n",
    "    model.add(Conv1D(256, 3, activation='relu'))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "\n",
    "    model.add(Dense(500, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dropout(0.1))\n",
    "    \n",
    "    if OPTIMIZER == 'adam':\n",
    "        optimizer = Adam(learning_rate=LR)\n",
    "    elif OPTIMIZER == 'rmsprop':\n",
    "        optimizer = RMSprop(learning_rate=LR)\n",
    "    \n",
    "    model.compile(optimizer=optimizer, loss=LOSS_FUNCTION, metrics=[METRIC1])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1D CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_1d_cnn(trial=None)\n",
    "history = model.fit(X_train, y_train, batch_size = BATCH_SIZE, epochs=EPOCHS, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,6))\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(history.history['loss'], label='Train loss', color='#8502d1')\n",
    "plt.plot(history.history['val_loss'], label='Validation loss', color='darkorange')\n",
    "plt.lengend()\n",
    "plt.title(\"Loss Evolution\")\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(history.history['accuracy'], label='Train Acc.', color='#8502d1')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Acc.', color='darkorange')\n",
    "plt.lengend()\n",
    "plt.title(\"Accuracy Evolution\")\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
