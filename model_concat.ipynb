{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random \n",
    "import os\n",
    "import sys\n",
    "# import scipy.stats\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import ScalarFormatter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.losses import MeanAbsoluteError\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler, ModelCheckpoint\n",
    "from keras.layers import Input, Conv1D, Conv2D, MaxPooling1D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization, Concatenate,AveragePooling1D\n",
    "from keras.models import Model, load_model\n",
    "\n",
    "from keras.optimizers import Adam, RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow GPU availability:  [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "print(\"Tensorflow GPU availability: \", tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed=42):    \n",
    "    '''랜덤시드 고정. Hyperparm tuning 제외 모든 학습환경에서 \n",
    "    같은 성능이 나오게 합니다.'''\n",
    "    tf.random.set_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import data, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "MC_DROPOUT_MODE = 'ON' #ON/OFF\n",
    "targets_abs_max  = 0.0030516885275461087\n",
    "nb_dropout_wc = 1000\n",
    "nb_dropout = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = './output/'\n",
    "data_path = './data/'\n",
    "pred_path = './output/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data, metadata import\n",
    "test_adc_info = pd.read_csv(data_path + 'test_adc_info.csv', index_col='planet_id')\n",
    "train_labels = pd.read_csv(data_path + 'train_labels.csv', index_col='planet_id')\n",
    "sample_submission = pd.read_csv(data_path + 'sample_submission.csv', index_col='planet_id')\n",
    "wavelengths = pd.read_csv(data_path + 'wavelengths.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 40, 283, 1)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# testset_1d = np.load(pred_path + 'testset_1d.npy')\n",
    "testset_2d = np.load(pred_path + 'testset_2d.npy')\n",
    "testset_2d.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## predict wl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1D CNN (Predict mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cnn1d_model = load_model(model_path+'/model_cnn1d.h5', compile=False) # 현 tensorflow 버전 때문에 compile=False. Kaggle에선 떼고 사용할 것."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cnn1d_model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions_1d = cnn1d_model.predict(testset_1d)\n",
    "# predictions_1d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Postprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2D CNN (Predict shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn2d_model = load_model(model_path+'/model_cnn2d.h5', compile=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn2d_model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 3s 3s/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((1, 283), 0.0139748035, -0.010044133)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_2d = cnn2d_model.predict(testset_2d)\n",
    "predictions_2d.shape, predictions_2d.max(), predictions_2d.min()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Denormalize prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4.2646745e-05, -3.0651565e-05)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_2d = predictions_2d * targets_abs_max\n",
    "predictions_2d.max(), predictions_2d.min()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sum 1D result and 2D result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wl_prediction = predictions_2d + predictions_1d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## predict Uncertainty (Sigma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1D CNN uncertainty 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unstandardizing (data, min_train_valid, max_train_valid) : \n",
    "    return data * (max_train_valid - min_train_valid) + min_train_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MC_dropout_wc(model, data, nb_dropout):\n",
    "    predictions = np.zeros((nb.dropout, data.shape[0]))\n",
    "    for i in range(nb_dropout):\n",
    "        predictions[i,:] = model.prediction(data, verbose=0).flatten()\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if MC_DROPOUT_MODE=='ON':\n",
    "    print('Running...')\n",
    "    prediction_valid_wc = MC_dropout_wc(cnn1d_model, testset, nb_dropout_wc)\n",
    "    unstandardizing(prediction_valid_wc, min_train_valid_wc, max_train_valid_wc)\n",
    "    spectre_valid_wc, spectre_valid_std_wc = spectre_valid_wc_all.mean(axis = 0), spectre_valid_wc_all.std(axis = 0)\n",
    "    print('Done.')\n",
    "else:\n",
    "    spectre_valid_wc = cnn1d_model.predict(testset).flatten()\n",
    "    spectre_valid_wc = unstandardizing(spectre_valid_wc, min_train_valid_wc, max_train_valid_wc)\n",
    "    spectre_valid_std_wc = 0.1*np.abs(spectre_valid_wc)\n",
    "\n",
    "spectre_valid_wc, spectre_valid_std_wc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2D CNN uncertainty 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if MC_DROPOUT_MODE=='ON':\n",
    "    print('Running...')\n",
    "    prediction_valid_wc = MC_dropout_WC(model_wc, valid_wc, nb_dropout_wc)\n",
    "    spectre_valid_wc_all = unstandardizing(prediction_valid_wc, min_train_valid_wc, max_train_valid_wc)\n",
    "    spectre_valid_wc, spectre_valid_std_wc = spectre_valid_wc_all.mean(axis=0), spectre_valid_wc_all.std(axis=0)\n",
    "    print('Done')\n",
    "else:\n",
    "    spectre_valid_wc = model_wc.predict(valid_wc).flatten()\n",
    "    spectre_valid_wc = unstandardizing(spectre_valid_wc, min_train_valid_wc, max_train_valid_wc)\n",
    "    spectre_valid_std_wc = 0.1*np.abs(spectre_valid_wc)\n",
    "    \n",
    "spectre_valid_wc, spectre_valid_std_wc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation Score (GLL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_score(df, ground_truth, naive_mean, naive_sigma, sigma_true):\n",
    "    planet_id = df['planet_id']\n",
    "    y_pred = df.iloc[:, 1:284].values   # wl만 뽑기\n",
    "    sigma_pred = np.clip(df.iloc[:, 284:].values, a_min=10**-15, a_max=None) # sigma만 뽑기\n",
    "\n",
    "    y_true = ground_truth.drop_fts['planet_id'] # planet_id 삭제\n",
    "\n",
    "    GLL_pred = np.sum(scipy.stats.norm.logpdf(y_true, loc=y_pred, scale=sigma_pred))\n",
    "    GLL_true = np.sum(scipy.stats.norm.logpdf(y_true, loc=y_true, scale=sigma_true * np.ones_like(y_true)))\n",
    "    GLL_mean = np.sum(scipy.stats.norm.logpdf(y_true, loc=naive_mean * np.ones_like(y_true), scale=naive_sigma * np.ones_like(y_true)))\n",
    "\n",
    "    submit_score = (GLL_pred - GLL_mean) / (GLL_true - GLL_mean)\n",
    "    return float(np.clip(submit_score, 0.0, 1.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "naive_mean = 0.5\n",
    "naive_sigma = 0.1\n",
    "sigma_true = 1e-6\n",
    "\n",
    "score = calculate_score(y_pred, y_truth, naive_mean, naive_sigma, sigma_true)\n",
    "print(f'Validation Score: {score}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def postprocessing(pred, index, sigma_pred):\n",
    "    return pd.concat([pd.DataFrame(pred.clip(0, None), index=index, columns=wavelengths.columns),\n",
    "    pd.DataFrame(sigma_pred, index=index, columns=[f'sigma_{i}' for i in range(1, 284)])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = postprocessing(predictions_1d, test_adc_info.index, predictions_2d)\n",
    "\n",
    "submission.to_csv('submission.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
